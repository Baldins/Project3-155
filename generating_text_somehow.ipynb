{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HMM import unsupervised_HMM\n",
    "from HMM_helper import sample_sentence, parse_observations\n",
    "from preprocessing import read_files, featurize\n",
    "import numpy as np\n",
    "import random\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "# you have to install pyphen\n",
    "from nltk.corpus import cmudict\n",
    "import pyphen\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punct(s):\n",
    "    '''\n",
    "    This function strips the punctuation of any given string. \n",
    "    Input: \n",
    "        s: string to strip punctuation from \n",
    "    Output: \n",
    "        string stripped of punctuation\n",
    "    '''\n",
    "    # newPunct = punctuation.replace(\"'\", \"\")\n",
    "    # newPunct = punctuation.replace(\"-\", \"\")\n",
    "    newPunct = '''!\"#$%&()*+,./:;<=>?@[\\]^_`{|}~'''\n",
    "    return ''.join(c for c in s if c not in newPunct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lower cell reads in the text file, then returns the list of words and the number of syllables in either the line or whole poem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(sep='poem'):\n",
    "    '''\n",
    "    This function reads the shakespeare and syllable files given to us.\n",
    "    Input: \n",
    "        sep: either 'line' or 'poem'. If line, shakeLines is a separate entry \n",
    "            per line, and if poem, shakeLines is a separate entry per poem\n",
    "    Output: \n",
    "        shakeLines: A 2D list with each element being a list of the words in the\n",
    "            line or poem\n",
    "        syllables: a dictionary with each key being a word and it's value \n",
    "            being how many syllables it has. The changed number of syllables\n",
    "            with the word being at the end of a line is currently ignored.\n",
    "    '''\n",
    "\n",
    "    # format: each line is an individual list of words in that line\n",
    "    shakeLines = []\n",
    "    # read in the shakespeare poems \n",
    "    if sep == 'line':\n",
    "        with open(\"./data/shakespeare.txt\") as poems:\n",
    "            for index, line in enumerate(poems):\n",
    "                # super jank way to get rid of line numbers, but it works!\n",
    "                if line != \"\\n\" and len(line) != 23 and len(line) != 22 and len(line) != 21:\n",
    "                    line = line.lower()\n",
    "                    shakeLines.append(re.findall(r\"[\\w']+\", strip_punct(line.rstrip(\"\\n\"))))\n",
    "    \n",
    "    # format: each poem is an individual list of words in that poem\n",
    "    if sep == 'poem':\n",
    "        file = open(\"./data/shakespeare.txt\")\n",
    "        data = file.read()\n",
    "        paragraph = data.split(\"\\n\\n\\n\")\n",
    "        for poem in paragraph:\n",
    "            poem = poem.replace('\\n', ' ')\n",
    "            poem = poem.lstrip()\n",
    "            poem = poem.split(' ', 1)[1]\n",
    "            poem = poem.lower()\n",
    "            shakeLines.append(re.findall(r\"[\\w']+\", strip_punct(poem.rstrip(\"\\n\"))))\n",
    "\n",
    "\n",
    "    # format: dictionary of how many syllables each word is\n",
    "    # note that syllable differences at end of lines are ignored\n",
    "    syllables = {}\n",
    "    with open(\"./data/Syllable_dictionary.txt\") as syllDict:\n",
    "        for line in syllDict:\n",
    "            split = line.split()\n",
    "            if len(split) == 3:\n",
    "                (key, end, val) = line.split()\n",
    "            else:\n",
    "                (key, val) = line.split()\n",
    "\n",
    "            # they're ordered by syllable length, so sometimes the E is last\n",
    "            try:\n",
    "                syllables[key] = int(val)\n",
    "            except:\n",
    "                syllables[key] = int(end)\n",
    "\n",
    "    rhymes = {}\n",
    "    if sep == 'line':\n",
    "        # print(shakeLines)\n",
    "        # sonnet format: abab cdcd efef gg\n",
    "        for j in range(len(shakeLines)-1):\n",
    "            line = shakeLines[j]\n",
    "            last_word = line[-1]\n",
    "            i = (j % 14) + 1\n",
    "            # abab\n",
    "            if i == 1 or i == 2 or i == 5 or i == 6 or i == 9 or i == 10:\n",
    "                rhymes = make_rhyming_dictionary(rhymes, last_word, shakeLines[j+2][-1])\n",
    "            # elif i == 3 or i == 4 or i == 7 or i == 8 or i == 11 or i == 12:\n",
    "                # rhymes = make_rhyming_dictionary(rhymes, last_word, shakeLines[j-2][-1])\n",
    "            elif i == 13:\n",
    "                rhymes = make_rhyming_dictionary(rhymes, last_word, shakeLines[j+1][-1])\n",
    "            # elif i == 14:\n",
    "            #     rhymes = make_rhyming_dictionary(rhymes, last_word, shakeLines[j-1][-1])\n",
    "\n",
    "    return shakeLines, syllables, rhymes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next function returns the sequences in the lines (not sure what this is to be honest), a dictionary with their encoding and the features (tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(lines):\n",
    "    '''\n",
    "    This function returns the feature representation of a set of lines.\n",
    "    Input: \n",
    "        lines: An iterable object with each element being a list of strings\n",
    "    Output: \n",
    "        possiblePOS: the list of possible parts of speech, where the index of \n",
    "            each POS being the its number in the \n",
    "        POSlookup:  A 2D array being POS, [word, frequency] for the given POS\n",
    "        features: The feature representation of the input\n",
    "    '''\n",
    "    possiblePOS = []\n",
    "    POSlookup = []\n",
    "    features = []\n",
    "    for obs in lines:\n",
    "        # POS is a list of tuples being (word, POS)\n",
    "        POS = pos_tag(obs)\n",
    "        poemFeatures = []\n",
    "        # if it's a new POS, add it to the list\n",
    "        for pair in POS: \n",
    "            if pair[1] not in possiblePOS:\n",
    "                possiblePOS.append(pair[1])\n",
    "                POSlookup.append([])\n",
    "                POSlookup[possiblePOS.index(pair[1])].append([pair[0], 1])\n",
    "            else: \n",
    "                firstCol = [row[0] for row in POSlookup[possiblePOS.index(pair[1])]]\n",
    "                if pair[0] not in firstCol:\n",
    "                    POSlookup[possiblePOS.index(pair[1])].append([pair[0], 1])\n",
    "                else:\n",
    "                    index = firstCol.index(pair[0])\n",
    "                    POSlookup[possiblePOS.index(pair[1])][index][1] += 1\n",
    "            # we are simply indexing using the order in which they appear\n",
    "\n",
    "            poemFeatures.append(possiblePOS.index(pair[1]))\n",
    "            # print(POSlookup[possiblePOS.index(pair[1])])\n",
    "            \n",
    "\n",
    "\n",
    "        features.append(poemFeatures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function below calls featurize. Syllables is provided by calling 'read_files' above\n",
    "\n",
    "example:\n",
    "poems, syllables, _ = read_files(sep='poem')\n",
    "lines, syllables, rhymes = read_files(sep='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(emission, POSlookup, syllables, reverse=False, lastWord=None):\n",
    "\t'''\n",
    "\tThis function generates a string given the emissions and the probabilities \n",
    "\tof a word being emitted given a certain\n",
    "\tInput:\n",
    "\t\temission: The list of emission, which represents the POS of the word\n",
    "\t\tPOSlookup: A 2D array being POS, [word, frequency] for the given POS\n",
    "\t\tsyllables: The dictionary of words and number of syllables each word has\n",
    "\t\treverse: Whether to start from beginning or end of line\n",
    "\t\trhymes: Dictionary of different rhymes\n",
    "\tOutput:\n",
    "\t\temStr: The sentence generated\n",
    "\t'''\n",
    "\tdone = False\n",
    "\tif reverse:\n",
    "\t\tassert(lastWord is not None)\n",
    "\t\twhile not done:\n",
    "\t\t\temStr = lastWord\n",
    "\t\t\ttry:\n",
    "\t\t\t\tsyllableCount = syllables[lastWord]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tsyllableCount = 2\n",
    "\t\t\t\tprint(lastWord)\n",
    "\t\t\tfor obs in emission:\n",
    "\t\t\t\temRate = [row[1] for row in POSlookup[obs]]\n",
    "\t\t\t\temWords = [row[0] for row in POSlookup[obs]]\n",
    "\t\t\t\temRate = np.array(emRate)\n",
    "\t\t\t\temRate = emRate/sum(emRate)\n",
    "\n",
    "\t\t\t\tindex = np.random.choice(np.arange(len(emRate)), p=emRate)\n",
    "\t\t\t\tnewWord = emWords[index]\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tsyllableCount += syllables[newWord]\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tsyllableCount += 2\n",
    "\t\t\t\t\tprint(newWord)\n",
    "\t\t\t\temStr = newWord + ' ' + emStr\n",
    "\t\t\t\tif syllableCount == 10:\n",
    "\t\t\t\t\tdone = True\n",
    "\t\t\t\t\tbreak\n",
    "\telse:\n",
    "\t\twhile not done:\n",
    "\t\t\temStr = ''\n",
    "\t\t\tsyllableCount = 0\n",
    "\t\t\tfor obs in emission: \n",
    "\t\t\t\temRate = [row[1] for row in POSlookup[obs]]\n",
    "\t\t\t\temWords = [row[0] for row in POSlookup[obs]]\n",
    "\t\t\t\temRate = np.array(emRate)\n",
    "\t\t\t\temRate = emRate/sum(emRate)\n",
    "\n",
    "\t\t\t\tindex = np.random.choice(np.arange(len(emRate)), p=emRate)\n",
    "\t\t\t\tnewWord = emWords[index]\n",
    "\t\t\t\tsyllableCount += syllables[newWord]\n",
    "\t\t\t\temStr = emStr + newWord + ' '\n",
    "\t\t\t\tif syllableCount == 10:\n",
    "\t\t\t\t\tdone = True\n",
    "\t\t\t\t\tbreak\n",
    "\treturn emStr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sonnet(poems, lines, syllables, rhymes=None):\n",
    "\tPOSList, POSlookup, features = featurize(poems)\n",
    "\tHMM = unsupervised_HMM(features, 25, 100)\n",
    "\temission, states = HMM.generate_emission(10)\n",
    "\tif rhymes is None:\n",
    "\t\tsonnet = \"\"\n",
    "\t\tfor i in range(14):\n",
    "\t\t\tline = generate_words(emission, POSlookup, syllables)\n",
    "\t\t\tsonnet = sonnet + line + \"\\n\"\n",
    "\n",
    "\telse:\n",
    "\t\t# abab cdcd efef gg\n",
    "\t\tsonnet = [\"\" for x in range(14)]\n",
    "\t\tline_idx = [0, 1, 4, 5, 8, 9, 12]\n",
    "\t\tfor i in line_idx:\n",
    "\t\t\t# choose a random word in the dictionary\n",
    "\t\t\tkey, val = random.choice(list(rhymes.items()))\n",
    "\t\t\t# choose a random word that rhymes with the previous one\n",
    "\t\t\tpair = np.random.choice(val)\n",
    "\t\t\tsonnet[i] += str(key)\n",
    "\t\t\tif i < 12:\n",
    "\t\t\t\tsonnet[i+2] += str(pair)\n",
    "\t\t\telse:\n",
    "\t\t\t\tsonnet[i+1] += str(pair)\n",
    "\t\tfor i in range(len(sonnet)):\n",
    "\t\t\tline = generate_words(emission, POSlookup, syllables, True, sonnet[i])\n",
    "\t\t\tsonnet[i] = line\n",
    "\t\tsonnet = \"\\n\".join(sonnet)\n",
    "\tprint(sonnet)\n",
    "\treturn sonnet\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
