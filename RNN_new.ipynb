{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout, Lambda\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/shakespeare.txt') as f:\n",
    "    text = f.read()\n",
    "    text = text.lower()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# chars = [x for x in chars if x not in newPun] # changed from newPunct\n",
    "\n",
    "# correct mappings\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "int_to_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "\n",
    "n_chars = len(chars)\n",
    "text_length = len(text)\n",
    "\n",
    "sentence_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "lstm_size = 200\n",
    "num_epochs = 100\n",
    "sequence_length = 40\n",
    "\n",
    "sentence_length = sequence_length\n",
    "skip = 1\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0,len(text)-sentence_length, skip):\n",
    "    seq_in = text[i:i + sentence_length]\n",
    "    seq_out = text[i + sentence_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "num_sentences = len(dataX)\n",
    "\n",
    "X = np.zeros((num_sentences, sentence_length, n_chars), dtype=np.bool)\n",
    "y = np.zeros((num_sentences, n_chars), dtype=np.bool)\n",
    "\n",
    "for i, sent in enumerate(dataX):\n",
    "    for j, n_c in enumerate(sent):\n",
    "        X[i, j, n_c] = 1\n",
    "    y[i, dataY[i]] = 1\n",
    "\n",
    "# reshape X to be [samples, time steps, features]\n",
    "# X = np.array([to_categorical(seq, num_classes=n_chars) for seq in dataX])\n",
    "# # normalize\n",
    "# X = X / float(n_chars)\n",
    "# # one hot encode the output variable\n",
    "# y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/francescabaldini/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# I'm hard coding temp in the Lmbda line for ease of loading, temp = 0.2\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(sentence_length, n_chars)))\n",
    "model.add(Dense(n_chars, activation='softmax'))\n",
    "model.add(Lambda(lambda x: x / 1.2))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/francescabaldini/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "97989/97989 [==============================] - 193s 2ms/step - loss: 2.5005\n",
      "Epoch 2/100\n",
      "97989/97989 [==============================] - 183s 2ms/step - loss: 2.0341\n",
      "Epoch 3/100\n",
      "97989/97989 [==============================] - 151s 2ms/step - loss: 1.8657\n",
      "Epoch 4/100\n",
      "97989/97989 [==============================] - 151s 2ms/step - loss: 1.7655\n",
      "Epoch 5/100\n",
      "97989/97989 [==============================] - 154s 2ms/step - loss: 1.6886\n",
      "Epoch 6/100\n",
      "97989/97989 [==============================] - 160s 2ms/step - loss: 1.6292\n",
      "Epoch 7/100\n",
      "97989/97989 [==============================] - 160s 2ms/step - loss: 1.5809\n",
      "Epoch 8/100\n",
      "97989/97989 [==============================] - 161s 2ms/step - loss: 1.5312\n",
      "Epoch 9/100\n",
      "97989/97989 [==============================] - 162s 2ms/step - loss: 1.4896\n",
      "Epoch 10/100\n",
      "97989/97989 [==============================] - 160s 2ms/step - loss: 1.4498\n",
      "Epoch 11/100\n",
      "97989/97989 [==============================] - 160s 2ms/step - loss: 1.4098\n",
      "Epoch 12/100\n",
      "97989/97989 [==============================] - 162s 2ms/step - loss: 1.3714\n",
      "Epoch 13/100\n",
      "97989/97989 [==============================] - 164s 2ms/step - loss: 1.3322\n",
      "Epoch 14/100\n",
      "97989/97989 [==============================] - 164s 2ms/step - loss: 1.2931\n",
      "Epoch 15/100\n",
      "97989/97989 [==============================] - 178s 2ms/step - loss: 1.2529\n",
      "Epoch 16/100\n",
      "97989/97989 [==============================] - 10933s 112ms/step - loss: 1.2129\n",
      "Epoch 17/100\n",
      "97989/97989 [==============================] - 2617s 27ms/step - loss: 1.1711\n",
      "Epoch 18/100\n",
      "29952/97989 [========>.....................] - ETA: 1:57 - loss: 1.1078"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=num_epochs, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
