{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout, Lambda\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f = open(os.getcwd()+'/data/shakespeare.txt')\n",
    "lines = f.readlines()\n",
    "new_text_list = []\n",
    "all_words = []\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.lower()\n",
    "    newPunct = \"!#$%&()*'+,./:;<=>?@[\\]^_`{|}~1234567890-' '\"\n",
    "    if len(line) > 2:\n",
    "        new_text += ''.join(c for c in line if c not in newPunct)\n",
    "    if line.isdigit()==False:\n",
    "        all_words.append(line)\n",
    "\n",
    "og_text = [x for x in all_words if x != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type(og_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uselessChar = ['!','#','$','%','&','*','(',')',\"'\",'*','+',',','.','/',':',';','<','=','>','?','@','[',']','^','_','{','}','~','1','2', '3','4','5','6','7','8','9','0','-',' ']\n",
    "# new_text = [x for x in new_text if x not in uselessChar]\n",
    "# #new_text = str(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chars = sorted(list(set(new_text)))\n",
    "chars = [x for x in chars if x not in newPunct]\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = {i:ch for i, ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text = open(os.getcwd()+'/data/shakespeare.txt').read()\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the text\n",
    "# f = open(os.getcwd()+'/data/shakespeare.txt')\n",
    "# text = f.readlines()\n",
    "\n",
    "# text = open('data/shakespeare.txt', 'r').read()\n",
    "# text = text.lower()\n",
    "\n",
    "f = open(os.getcwd()+'/data/shakespeare.txt')\n",
    "lines = f.readlines()\n",
    "all_words = []\n",
    "new_text = \"\"\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    line = line.lower()\n",
    "    newPunct = \"!#$%&()*'+,./:;<=>?@[\\]^_`{|}~1234567890-' '\"\n",
    "    if len(line) > 0:\n",
    "        new_text += ''.join(c for c in line if c not in newPunct)\n",
    "    if line.isdigit()==False:\n",
    "        all_words.append(line)\n",
    "\n",
    "# text with structure\n",
    "og_text = [x for x in all_words if x != []]\n",
    "\n",
    "# correct characters and dictionary\n",
    "chars = sorted(list(set(new_text)))\n",
    "chars = [x for x in chars if x not in newPunct]\n",
    "\n",
    "# correct mappings\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "\n",
    "n_chars = len(new_text)\n",
    "n_vocab = len(chars)\n",
    "\n",
    "\n",
    "num_chars = len(chars)\n",
    "# print \"Total Characters: \", n_chars\n",
    "# print \"Total Vocab: \", n_vocab\n",
    "\n",
    "\n",
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 40\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = new_text[i:i + seq_length]\n",
    "\tseq_out = new_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "# print \"Total Patterns: \", n_patterns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.array([to_categorical(seq, num_classes=n_vocab) for seq in dataX])\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72915, 40, 26)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 72915 x 40 \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], num_chars)))\n",
    "model.add(Dense(num_chars, activation='softmax'))\n",
    "model.add(Lambda(lambda x: x / temp))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72915, 40, 26)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "72915/72915 [==============================] - 140s 2ms/step - loss: 2.9030\n",
      "Epoch 2/30\n",
      "72915/72915 [==============================] - 147s 2ms/step - loss: 2.8705\n",
      "Epoch 3/30\n",
      "72915/72915 [==============================] - 136s 2ms/step - loss: 2.7275\n",
      "Epoch 4/30\n",
      "72915/72915 [==============================] - 130s 2ms/step - loss: 2.5904\n",
      "Epoch 5/30\n",
      "72915/72915 [==============================] - 132s 2ms/step - loss: 2.5169\n",
      "Epoch 6/30\n",
      "72915/72915 [==============================] - 136s 2ms/step - loss: 2.4629\n",
      "Epoch 7/30\n",
      "72915/72915 [==============================] - 157s 2ms/step - loss: 2.4232\n",
      "Epoch 8/30\n",
      "72915/72915 [==============================] - 144s 2ms/step - loss: 2.3917\n",
      "Epoch 9/30\n",
      "72915/72915 [==============================] - 146s 2ms/step - loss: 2.3661\n",
      "Epoch 10/30\n",
      "72915/72915 [==============================] - 147s 2ms/step - loss: 2.3409\n",
      "Epoch 11/30\n",
      "72915/72915 [==============================] - 144s 2ms/step - loss: 2.3147\n",
      "Epoch 12/30\n",
      "72915/72915 [==============================] - 146s 2ms/step - loss: 2.2906\n",
      "Epoch 13/30\n",
      "72915/72915 [==============================] - 136s 2ms/step - loss: 2.2673\n",
      "Epoch 14/30\n",
      "72915/72915 [==============================] - 135s 2ms/step - loss: 2.2423\n",
      "Epoch 15/30\n",
      "72915/72915 [==============================] - 135s 2ms/step - loss: 2.2179\n",
      "Epoch 16/30\n",
      "72915/72915 [==============================] - 135s 2ms/step - loss: 2.1917\n",
      "Epoch 17/30\n",
      "72915/72915 [==============================] - 142s 2ms/step - loss: 2.1647\n",
      "Epoch 18/30\n",
      "72915/72915 [==============================] - 133s 2ms/step - loss: 2.1353\n",
      "Epoch 19/30\n",
      "72915/72915 [==============================] - 143s 2ms/step - loss: 2.1049\n",
      "Epoch 20/30\n",
      "72915/72915 [==============================] - 464s 6ms/step - loss: 2.0737\n",
      "Epoch 21/30\n",
      "72915/72915 [==============================] - 322s 4ms/step - loss: 2.0391\n",
      "Epoch 22/30\n",
      "72915/72915 [==============================] - 283s 4ms/step - loss: 2.0034\n",
      "Epoch 23/30\n",
      "72915/72915 [==============================] - 313s 4ms/step - loss: 1.9694\n",
      "Epoch 24/30\n",
      "72915/72915 [==============================] - 355s 5ms/step - loss: 1.9305\n",
      "Epoch 25/30\n",
      "72915/72915 [==============================] - 315s 4ms/step - loss: 1.8912\n",
      "Epoch 26/30\n",
      "72915/72915 [==============================] - 374s 5ms/step - loss: 1.8521\n",
      "Epoch 27/30\n",
      "72915/72915 [==============================] - 268s 4ms/step - loss: 1.8132\n",
      "Epoch 28/30\n",
      "72915/72915 [==============================] - 189s 3ms/step - loss: 1.7713\n",
      "Epoch 29/30\n",
      "72915/72915 [==============================] - 191s 3ms/step - loss: 1.7307\n",
      "Epoch 30/30\n",
      "72915/72915 [==============================] - 186s 3ms/step - loss: 1.6899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110f10470>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_rnn.h5')\n",
    "\n",
    "# loaded_rnn = model_load('my_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, encoding, seed_text, num_chars, sequence_length, max_prob=False):\n",
    "\t'''\n",
    "\tThis function uses the trained model and encoding map to generate text\n",
    "\tof a sonnet for the requested number of characters, each time using the last \n",
    "\tsequence_length characters to predict the next character.\n",
    "\tInput:\n",
    "\t\tmodel: The trained model\n",
    "\t\tencoding: the mapping of characters to integers\n",
    "\t\tseed_text: the initial text used to predict the next characters\n",
    "\t\tnum_chars: the number of characters we want to predict\n",
    "\t\tsequence_length: length of the sequences trained on\n",
    "\t\tmax_prob: \n",
    "\t\t\tTrue = take the highest probability character\n",
    "\t\t\tFalse = take a character based on the probability distribution\n",
    "\t\n",
    "\tOuput:\n",
    "\t\tnew_text: text with num_chars characters of generated text in \n",
    "\t\t\t\t  addition to the seed text\n",
    "\t'''\n",
    "\t# Initialize with this seed text\n",
    "\tnew_text = seed_text\n",
    "\tfor _ in range(num_chars):\n",
    "\t\t# Convert current sequence from characters to integers\n",
    "\t\tsequence = [encoding[char] for char in new_text]\n",
    "\t\t# Only look at the newest 40 characters\n",
    "\t\tsequence = pad_sequences([sequence], maxlen=40, truncating='pre')\n",
    "\t\t# Apply one-hot encoding\n",
    "\t\tencoded_sequence = to_categorical(sequence, num_classes=len(encoding))\n",
    "\t\tif max_prob:\n",
    "\t\t\t# Predict character by max probability\n",
    "\t\t\tprob_index = model.predict_classes(encoded_sequence)\n",
    "\t\telse:\n",
    "\t\t\t# Predict character by probability distribution\n",
    "\t\t\tprob_indices = model.predict(encoded_sequence)[0]\n",
    "\t\t\tprob_index = np.random.choice(range(len(prob_indices)), p=prob_indices)\n",
    "\t\t# Convert integer back to character\n",
    "\t\tnew_char = ''\n",
    "\t\tfor char, index in encoding.items():\n",
    "\t\t\tif index == prob_index:\n",
    "\t\t\t\tnew_char = char\n",
    "\t\t\t\tbreak\n",
    "\t\tnew_text += new_char\n",
    "\n",
    "\treturn new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWordFrequency(input):\n",
    "    f = open(artist_file,'r')\n",
    "    words = [x for y in [l.split() for l in f.readlines()] for x in y]\n",
    "    data = sorted([(w, words.count(w)) for w in set(words)], key = lambda x:x[1], reverse=True)[:40] \n",
    "    most_words = [x[0] for x in data]\n",
    "    times_used = [int(x[1]) for x in data]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.bar(x=sorted(most_words), height=times_used, color = 'grey', edgecolor = 'black',  width=.5)\n",
    "    plt.xticks(rotation=45, fontsize=18)\n",
    "    plt.yticks(rotation=0, fontsize=18)\n",
    "    plt.xlabel('Most Common Words:', fontsize=18)\n",
    "    plt.ylabel('Number of Occurences:', fontsize=18)\n",
    "    plt.title('Most Commonly Used Words: %s' % (artist_file), fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "#  the keras model which is trained is defined as 'model' in this example\n",
    "model_json = model.to_json()\n",
    "\n",
    "\n",
    "with open(\"model_num.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_num.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fcb4b443d2d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloaded_model_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# load weights into new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 145\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    299\u001b[0m             layer = layer_module.deserialize(conf,\n\u001b[1;32m    300\u001b[0m                                              custom_objects=custom_objects)\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_chars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    "temp = 0.2 # this is essential\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model_num.json', 'r')\n",
    "\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_num.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.save('model_num.hdf5')\n",
    "loaded_model=load_model('model_num.hdf5') # this is complaining that 'temp' isn't initialized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnet = generate_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
